name: Deploy boltfoundry-com

on:
  push:
    branches: [main]
    paths:
      - "apps/boltfoundry-com/**"
      - "infra/terraform/hetzner/**"
  workflow_dispatch:

# Prevent concurrent Terraform operations
concurrency:
  group: terraform-state
  cancel-in-progress: false

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      id-token: write
    steps:
      - uses: actions/checkout@v4

      - uses: DeterminateSystems/nix-installer-action@main
      # - uses: DeterminateSystems/flakehub-cache-action@main  # Disabled FlakeHub caching

      - name: Build binary and sync production env
        run: |
          nix develop .#production --accept-flake-config --command bash -c "
            # Sync environment variables from vault accessible by service account
            # The OP_SERVICE_ACCOUNT_TOKEN determines which vault is used
            if [ -n \"${{ secrets.PRODUCTION_OP_SERVICE_ACCOUNT_TOKEN }}\" ]; then
              bft sitevar sync --force
            fi
            # Build the binary
            bft compile boltfoundry-com
          "
        env:
          OP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.PRODUCTION_OP_SERVICE_ACCOUNT_TOKEN }}

      - name: Login to GitHub Container Registry
        run: echo ${{ secrets.GITHUB_TOKEN }} | docker login ghcr.io -u ${{ github.actor }} --password-stdin

      - name: Build and push Docker image
        run: |
          # Build with git hash and latest tags
          docker build \
            -t ghcr.io/${{ github.repository_owner }}/boltfoundry-com:${{ github.sha }} \
            -f infra/Dockerfile.deploy \
            --build-arg BINARY_PATH=build/boltfoundry-com \
            --build-arg BINARY_NAME=boltfoundry-com \
            .
          docker tag ghcr.io/${{ github.repository_owner }}/boltfoundry-com:${{ github.sha }} ghcr.io/${{ github.repository_owner }}/boltfoundry-com:latest
          docker push ghcr.io/${{ github.repository_owner }}/boltfoundry-com:${{ github.sha }}
          docker push ghcr.io/${{ github.repository_owner }}/boltfoundry-com:latest

      - name: Setup SSH
        run: |
          # First sync secrets from 1Password to get SSH_PRIVATE_KEY
          nix develop .#production --accept-flake-config --command bash -euc "
            export OP_SERVICE_ACCOUNT_TOKEN='${{ secrets.PRODUCTION_OP_SERVICE_ACCOUNT_TOKEN }}'
            # Sync all secrets from 1Password
            # Note: We only sync secrets here for SSH setup
            # Full sync happens in the deployment step
            bft sitevar sync --force --secret-only
          "

          # Now source the secrets file and setup SSH outside of Nix shell
          # This ensures the SSH key persists for subsequent steps
          source .env.secrets

          # Start SSH agent and add the key
          eval "$(ssh-agent -s)"

          # Setup SSH directory and key
          mkdir -p ~/.ssh

          # Write the SSH key to file
          echo "$SSH_PRIVATE_KEY" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa

          # Try to validate the key format
          echo "Validating SSH key format..."
          ssh-keygen -y -f ~/.ssh/id_rsa > /dev/null 2>&1 && echo "Key format is valid" || echo "Key format is INVALID"

          # Verify the key is valid before proceeding
          if ! ssh-keygen -y -f ~/.ssh/id_rsa > /dev/null 2>&1; then
            echo "ERROR: SSH key format is invalid"
            echo "Key content first 50 chars: $(head -c 50 ~/.ssh/id_rsa)"
            echo "Key content last 50 chars: $(tail -c 50 ~/.ssh/id_rsa)"
            # Don't exit yet - let's try to continue without SSH agent
            echo "Will attempt to continue without SSH agent"
          else
            # Add the key to the SSH agent only if it's valid
            ssh-add ~/.ssh/id_rsa || echo "Failed to add key to SSH agent, continuing anyway"
          fi

          # Export SSH_AUTH_SOCK for subsequent steps
          echo "SSH_AUTH_SOCK=$SSH_AUTH_SOCK" >> $GITHUB_ENV

          # Note: ssh-keyscan will be done after we have the server IP
        env:
          OP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.PRODUCTION_OP_SERVICE_ACCOUNT_TOKEN }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Sync secrets and generate Kamal config from Terraform state
        id: terraform_output
        run: |
          # First sync secrets from 1Password
          nix develop .#production --accept-flake-config --command bash -euc "
            export OP_SERVICE_ACCOUNT_TOKEN='${{ secrets.PRODUCTION_OP_SERVICE_ACCOUNT_TOKEN }}'

            # Sync all secrets to .env.secrets
            bft sitevar sync --force

            # Source the secrets
            source .env.secrets

            # Export variables for Terraform
            export TF_VAR_hcloud_token=\$HETZNER_API_TOKEN
            export TF_VAR_cloudflare_api_token=\$CLOUDFLARE_API_TOKEN
            export TF_VAR_cloudflare_zone_id=\$CLOUDFLARE_ZONE_ID
            export TF_VAR_ssh_public_key=\$SSH_PUBLIC_KEY
            export TF_VAR_hyperdx_api_key=\$HYPERDX_API_KEY
            export TF_VAR_s3_access_key=\$AWS_ACCESS_KEY_ID
            export TF_VAR_s3_secret_key=\$AWS_SECRET_ACCESS_KEY
            export TF_VAR_github_token=\$GITHUB_PERSONAL_ACCESS_TOKEN
            export TF_VAR_hetzner_project_id=\$HETZNER_PROJECT_ID
            export TF_VAR_s3_endpoint=\$S3_ENDPOINT

            # Use CI credentials for Terraform backend
            export AWS_ACCESS_KEY_ID=\$TERRAFORM_BACKEND_ACCESS_KEY_ID
            export AWS_SECRET_ACCESS_KEY=\$TERRAFORM_BACKEND_SECRET_ACCESS_KEY

            # Get server IP from Terraform state (read-only operation)
            cd infra/terraform/hetzner
            # Map backend endpoint to S3 endpoint for consistency
            export TERRAFORM_S3_ENDPOINT=\$TERRAFORM_BACKEND_ENDPOINT
            terraform init -backend-config=\"endpoint=\$TERRAFORM_S3_ENDPOINT\"

            # Just read the floating IP from state, don't modify anything
            FLOATING_IP=\$(terraform output -raw server_ip 2>/dev/null || echo '')

            if [ -z \"\$FLOATING_IP\" ]; then
              echo \"❌ Could not get server IP from Terraform state\"
              echo \"\"
              echo \"This usually means the infrastructure hasn't been deployed yet.\"
              echo \"Please ensure the infrastructure workflow has run successfully first:\"
              echo \"  1. Go to Actions → Deploy Infrastructure (Hetzner)\"
              echo \"  2. Click 'Run workflow' and deploy the infrastructure\"
              echo \"  3. Once successful, re-run this deployment workflow\"
              echo \"\"
              echo \"Alternatively, if infrastructure was recently destroyed, you'll need to redeploy it first.\"
              exit 1
            fi

            # Store the IP for the deployment step
            echo \"BOLTFOUNDRY_COM_SERVER_IP=\$FLOATING_IP\" >> .env.secrets

            # Output the IP for GitHub Actions to use in next steps
            echo \"server_ip=\$FLOATING_IP\" >> \$GITHUB_OUTPUT
          "

          # Add server to known_hosts outside of Nix shell to ensure it persists
          # Use the server IP from the output
          ssh-keyscan -H ${{ steps.terraform_output.outputs.server_ip }} >> ~/.ssh/known_hosts 2>/dev/null || true

      - name: Install Kamal
        run: sudo gem install kamal --version 2.7.0 --no-document

      - name: Check for stale deploy locks
        id: check-lock
        run: |
          echo "Checking for existing deploy locks..."
          SERVER_IP="${{ steps.terraform_output.outputs.server_ip }}"

          # Setup SSH for this check
          nix develop .#production --accept-flake-config --command bash -c "
            export OP_SERVICE_ACCOUNT_TOKEN='${{ secrets.PRODUCTION_OP_SERVICE_ACCOUNT_TOKEN }}'
            bft sitevar sync --force
            source .env.secrets

            mkdir -p ~/.ssh
            echo \"\$SSH_PRIVATE_KEY\" > ~/.ssh/id_rsa
            chmod 600 ~/.ssh/id_rsa

            echo \"Host $SERVER_IP\" >> ~/.ssh/config
            echo \"  StrictHostKeyChecking no\" >> ~/.ssh/config
            echo \"  UserKnownHostsFile /dev/null\" >> ~/.ssh/config
            chmod 600 ~/.ssh/config
          "

          # Check if lock exists and get its age
          if ssh root@$SERVER_IP "test -d .kamal/lock-boltfoundry-com"; then
            echo "Deploy lock found. Checking age..."

            # Get lock creation time
            LOCK_TIME=$(ssh root@$SERVER_IP "stat -c %Y .kamal/lock-boltfoundry-com" || echo "0")
            CURRENT_TIME=$(date +%s)
            LOCK_AGE=$((CURRENT_TIME - LOCK_TIME))

            # If lock is older than 30 minutes (1800 seconds), consider it stale
            if [ $LOCK_AGE -gt 1800 ]; then
              echo "Lock is older than 30 minutes ($LOCK_AGE seconds). Removing stale lock..."
              ssh root@$SERVER_IP "rm -rf .kamal/lock-boltfoundry-com"
              echo "✅ Stale lock removed"
            else
              echo "Lock is recent ($LOCK_AGE seconds old). Checking if deployment is active..."

              # Check if any kamal process is running
              if ! ssh root@$SERVER_IP "pgrep -f kamal > /dev/null 2>&1"; then
                echo "No active Kamal process found. Removing orphaned lock..."
                ssh root@$SERVER_IP "rm -rf .kamal/lock-boltfoundry-com"
                echo "✅ Orphaned lock removed"
              else
                echo "❌ Active deployment in progress. Cannot proceed."
                echo "To force unlock, run the 'Unlock Kamal Deploy' workflow manually."
                exit 1
              fi
            fi
          else
            echo "No existing deploy lock found ✅"
          fi

      - name: Deploy with Kamal
        run: |
          # Sync production config and secrets from 1Password and generate Kamal config
          nix develop .#production --accept-flake-config --command bash -c "
            export OP_SERVICE_ACCOUNT_TOKEN='${{ secrets.PRODUCTION_OP_SERVICE_ACCOUNT_TOKEN }}'

            # Sync ALL variables (both config and secrets) from 1Password
            bft sitevar sync --force

            # Restore the server IP that was retrieved from Terraform
            echo \"BOLTFOUNDRY_COM_SERVER_IP=${{ steps.terraform_output.outputs.server_ip }}\" >> .env.secrets

            # Generate Kamal config dynamically based on available secrets
            bft generate-kamal-config infra/terraform/hetzner/deploy.yml.tpl config/deploy.yml production

            # Create .env file for Kamal with config values only
            # Secrets are handled separately via .kamal/secrets for security
            cp .env.config .env
          "

          # Create .kamal directory and secrets file for Kamal 2.x
          mkdir -p .kamal

          # Start with the GitHub token for registry authentication
          echo "GITHUB_TOKEN=${KAMAL_REGISTRY_PASSWORD}" > .kamal/secrets

          # Copy all runtime secrets from .env.secrets to .kamal/secrets
          # This ensures Kamal has access to all secrets referenced in the config
          # Note: Config values from .env.config are passed via .env file
          if [ -f .env.secrets ]; then
            # Source the secrets and add them to .kamal/secrets
            # Skip infrastructure-only secrets that aren't needed at runtime
            source .env.secrets
            for var in $(grep "^[A-Z_]*=" .env.secrets | cut -d= -f1); do
              # Skip infrastructure and deployment secrets
              case "$var" in
                SSH_PRIVATE_KEY|SSH_PUBLIC_KEY|HETZNER_API_TOKEN|CLOUDFLARE_*|TERRAFORM_*|AWS_ACCESS_KEY_ID|AWS_SECRET_ACCESS_KEY|GITHUB_PERSONAL_ACCESS_TOKEN|HETZNER_PROJECT_ID|S3_ENDPOINT|*_SERVER_IP)
                  # Skip these - not needed at runtime
                  ;;
                *)
                  # Add runtime secret to .kamal/secrets
                  eval "value=\$$var"
                  if [ ! -z "$value" ]; then
                    echo "$var=$value" >> .kamal/secrets
                  fi
                  ;;
              esac
            done
          fi

          chmod 600 .kamal/secrets

          # Set up SSH for this step since GitHub Actions doesn't persist SSH agent between steps
          # We need to ensure the SSH key is available for Kamal
          if [ -f ~/.ssh/id_rsa ]; then
            echo "SSH key already exists at ~/.ssh/id_rsa"
            echo "Key fingerprint: $(ssh-keygen -lf ~/.ssh/id_rsa)"
          else
            echo "Setting up SSH key for Kamal deployment"
            source .env.secrets
            mkdir -p ~/.ssh
            echo "$SSH_PRIVATE_KEY" > ~/.ssh/id_rsa
            chmod 600 ~/.ssh/id_rsa
            echo "Created SSH key with fingerprint: $(ssh-keygen -lf ~/.ssh/id_rsa)"
          fi

          # Test SSH connection directly
          echo "Testing SSH connection to ${{ steps.terraform_output.outputs.server_ip }}..."
          ssh -o BatchMode=yes -o ConnectTimeout=5 root@${{ steps.terraform_output.outputs.server_ip }} "echo 'SSH connection successful'" || echo "Direct SSH test failed"

          # Ensure StrictHostKeyChecking is disabled for the deployment
          echo "Host ${{ steps.terraform_output.outputs.server_ip }}" >> ~/.ssh/config
          echo "  StrictHostKeyChecking no" >> ~/.ssh/config
          echo "  UserKnownHostsFile /dev/null" >> ~/.ssh/config
          chmod 600 ~/.ssh/config

          # Deploy with Kamal 2.x (will use .env for secret environment variables)
          # Use verbose mode to debug SSH issues
          kamal deploy --verbose
        env:
          KAMAL_REGISTRY_PASSWORD: ${{ secrets.GITHUB_TOKEN }}
          OP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.PRODUCTION_OP_SERVICE_ACCOUNT_TOKEN }}
          BOLTFOUNDRY_COM_SERVER_IP: ${{ steps.terraform_output.outputs.server_ip }}
        working-directory: ./

      - name: Validate deployment health
        run: |
          echo "🔍 Validating deployment health..."

          # Wait for deployment to stabilize
          echo "⏳ Waiting for deployment to stabilize..."
          sleep 30

          # Health check with retries
          echo "🩺 Testing health endpoint..."
          for i in {1..60}; do
            if curl -f -L -s https://boltfoundry.com/ > /dev/null 2>&1; then
              echo "✅ Health endpoint responded successfully"
              break
            fi
            if [ $i -eq 60 ]; then
              echo "❌ Health endpoint failed after 60 attempts (10 minutes)"
              echo "🔄 Attempting rollback..."
              kamal rollback --version=latest || echo "⚠️ Rollback command failed"
              exit 1
            fi
            echo "Health check attempt $i/60 failed, retrying in 10s..."
            sleep 10
          done

          # Test main page endpoint
          echo "🏠 Testing main page endpoint..."
          for i in {1..10}; do
            response_code=$(curl -L -s -o /dev/null -w "%{http_code}" https://boltfoundry.com/)
            if [ "$response_code" = "200" ]; then
              echo "✅ Main page responded with 200 OK"
              break
            fi
            if [ $i -eq 10 ]; then
              echo "❌ Main page failed with response code: $response_code"
              echo "🔄 Attempting rollback..."
              kamal rollback --version=latest || echo "⚠️ Rollback command failed"
              exit 1
            fi
            echo "Main page attempt $i/10 failed (response: $response_code), retrying in 10s..."
            sleep 10
          done

          # Enhanced health check - get detailed health info
          echo "🔬 Performing detailed health check..."
          health_response=$(curl -L -s https://boltfoundry.com/)
          if echo "$health_response" | grep -q 'html\|HTML'; then
            echo "✅ Detailed health check passed"
            echo "Health response contains HTML content"
          else
            echo "❌ Detailed health check failed - invalid response format"
            echo "Response: $health_response"
            echo "🔄 Attempting rollback..."
            kamal rollback || echo "⚠️ Rollback command failed"
            exit 1
          fi

          echo "🎉 Deployment validation successful!"

      - name: Monitor post-deployment stability
        run: |
          echo "👀 Monitoring deployment stability for 2 minutes..."

          # Monitor for 2 minutes to catch early failures
          for i in {1..12}; do
            response_code=$(curl -L -s -o /dev/null -w "%{http_code}" https://boltfoundry.com/)
            if [ "$response_code" != "200" ]; then
              echo "❌ Stability check failed with response code: $response_code at check $i/12"
              echo "🔄 Attempting rollback..."
              kamal rollback --version=latest || echo "⚠️ Rollback command failed"
              exit 1
            fi
            echo "✅ Stability check $i/12 passed (response: $response_code)"
            sleep 10
          done

          echo "🎯 Deployment is stable and healthy!"

      - name: Deployment success notification
        if: success()
        run: |
          echo "🚀 Deployment completed successfully!"
          echo "✅ Service URL: https://boltfoundry.com"
          echo "✅ Health Check: https://boltfoundry.com/"
          echo "✅ Deployment validated and stable"

      - name: Deployment failure notification
        if: failure()
        run: |
          echo "💥 Deployment failed!"
          echo "❌ Service may be unresponsive at: https://boltfoundry.com"
          echo "🔍 Check logs above for specific failure reason"
          echo "⚠️ Manual intervention may be required"
